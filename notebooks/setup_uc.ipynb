{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32a9e3a0-8ebb-4f0b-af94-5aaffb57b0e3",
   "metadata": {},
   "source": [
    "# Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2725dfa4-b6c4-4e2f-a1d4-91e25c4cf0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - hive</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://192.168.1.13:4041\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.3</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>local-uc-demo</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7c3a03fa8350>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "626d39d4-e526-4f65-a1e9-1dc11f022f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# Add project working directory to PATH\n",
    "sys.path.append(os.getenv(\"PROJECT_FOLDER\"))\n",
    "\n",
    "from src.utils import sql, register_spark_session\n",
    "\n",
    "# Register spark as global session\n",
    "register_spark_session(spark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28c840c7-b40e-4607-9a43-51a61875e1f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    CATALOG: unity\n",
      "    RAW_SCHEMA: raw\n",
      "    CURATED_SCHEMA: curated\n",
      "    PROJECT_FOLDER: /home/khoa-le/data/working/projects/unity-catalog-project\n",
      "    STORAGE_FOLDER: /home/khoa-le/data/storage/unity-catalog-project\n",
      "    UC_HOME: /home/khoa-le/data/app/uc/unitycatalog\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print our environments, including assigning and printing the values\n",
    "print(f\"\"\"\n",
    "    CATALOG: {(CATALOG := os.getenv(\"CATALOG\"))}\n",
    "    RAW_SCHEMA: {(RAW_SCHEMA := os.getenv(\"RAW_SCHEMA\"))}\n",
    "    CURATED_SCHEMA: {(CURATED_SCHEMA := os.getenv(\"CURATED_SCHEMA\"))}\n",
    "    PROJECT_FOLDER: {(PROJECT_FOLDER := os.getenv(\"PROJECT_FOLDER\"))}\n",
    "    STORAGE_FOLDER: {(STORAGE_FOLDER := os.getenv(\"STORAGE_FOLDER\"))}\n",
    "    UC_HOME: {(STORAGE_FOLDER := os.getenv(\"UC_HOME\"))}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac8ad401-d4fd-4d03-8dcb-c5a51c10031c",
   "metadata": {},
   "source": [
    "# Show Catalogs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5b97665b-8038-4787-860d-d20ae7c68dd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+\n",
      "|      catalog|\n",
      "+-------------+\n",
      "|spark_catalog|\n",
      "|        unity|\n",
      "+-------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# There are two catalogs by default: spark_catalog and unity\n",
    "spark.sql(\"SHOW CATALOGS;\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d5303ead-325a-4106-97de-345a5b1bfea0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|      raw|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# There is one default schema from `unity` catalog\n",
    "spark.sql(f\"SHOW SCHEMAS FROM {CATALOG};\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51b2997d-37ed-4798-a20f-ccf932986c04",
   "metadata": {},
   "source": [
    "# Create unity.raw schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75dd5cb8-7289-4fff-982b-ebc27cdb1a0e",
   "metadata": {},
   "source": [
    "This schema is used to store raw, unprocessed table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9250b473-bdc4-47e1-84f0-b2ac679f757e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f\"\"\"\n",
    "CREATE SCHEMA IF NOT EXISTS `{CATALOG}`.`{RAW_SCHEMA}`\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5da3a603-4c06-4a6b-84a9-e4a24c2e9b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+\n",
      "|namespace|\n",
      "+---------+\n",
      "|  default|\n",
      "|      raw|\n",
      "+---------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# With raw schema added, we now have both `raw` and `default`\n",
    "spark.sql(f\"SHOW SCHEMAS FROM {CATALOG};\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5311bd1-6d1e-4c72-9500-e5711f0f80a2",
   "metadata": {},
   "source": [
    "## Create tables under raw schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "42fe6808-e3bd-4136-9f5b-fae5b6048d00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create tables under this raw schema\n",
    "create_customers = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {CATALOG}.{RAW_SCHEMA}.customers (\n",
    "    customer_id STRING,\n",
    "    gender STRING,\n",
    "    first_name STRING,\n",
    "    last_name STRING,\n",
    "    email STRING,\n",
    "    yob INTEGER,\n",
    "    phone_number STRING,\n",
    "    job STRING,\n",
    "    address STRING,\n",
    "    first_transaction TIMESTAMP,\n",
    "    membership STRING,\n",
    "    last_processed_ts TIMESTAMP\n",
    ")\n",
    "USING DELTA\n",
    "LOCATION '{STORAGE_FOLDER}/{CATALOG}/{RAW_SCHEMA}/customers'\n",
    "COMMENT 'This table stores customer personal information'\n",
    "TBLPROPERTIES ('domain' = 'customer')\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query\n",
    "spark.sql(create_customers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "52168736-4053-4f3b-a8d2-f5d3415e6536",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_staffs = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {CATALOG}.{RAW_SCHEMA}.staffs (\n",
    "    staff_id STRING,\n",
    "    gender STRING,\n",
    "    first_name STRING,\n",
    "    last_name STRING,\n",
    "    store_id STRING,\n",
    "    last_processed_ts TIMESTAMP\n",
    ")\n",
    "USING DELTA\n",
    "LOCATION '{STORAGE_FOLDER}/{CATALOG}/{RAW_SCHEMA}/staffs'\n",
    "COMMENT 'This table stores staff information'\n",
    "TBLPROPERTIES ('domain' = 'staff')\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query\n",
    "spark.sql(create_staffs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bcc724e1-1366-4832-a99e-a6539d7cbb82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_stores = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {CATALOG}.{RAW_SCHEMA}.stores (\n",
    "    name STRING,\n",
    "    address STRING,\n",
    "    phone STRING,\n",
    "    email STRING,\n",
    "    last_processed_ts TIMESTAMP\n",
    ")\n",
    "USING DELTA\n",
    "LOCATION '{STORAGE_FOLDER}/{CATALOG}/{RAW_SCHEMA}/stores'\n",
    "COMMENT 'This table stores store information'\n",
    "TBLPROPERTIES ('domain' = 'store')\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query\n",
    "spark.sql(create_stores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "343bb6ab-e0df-4fe9-b49d-42985847b7fc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_products = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {CATALOG}.{RAW_SCHEMA}.products (\n",
    "    product_id STRING,\n",
    "    category STRING,\n",
    "    product_name STRING,\n",
    "    unit_price LONG,\n",
    "    last_processed_ts TIMESTAMP\n",
    ")\n",
    "USING DELTA\n",
    "LOCATION '{STORAGE_FOLDER}/{CATALOG}/{RAW_SCHEMA}/products'\n",
    "COMMENT 'This table stores product information'\n",
    "TBLPROPERTIES ('domain' = 'product')\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query\n",
    "spark.sql(create_products)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5359eda-00c2-4692-a16a-11d35bad9870",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "create_transactions = f\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS {CATALOG}.{RAW_SCHEMA}.transactions (\n",
    "    transaction_id STRING,\n",
    "    item_id STRING,\n",
    "    item_order INT,\n",
    "    store STRING,\n",
    "    customer_id STRING,\n",
    "    staff_id STRING,\n",
    "    quantity INT,\n",
    "    utc_dt STRING,\n",
    "    last_processed_ts TIMESTAMP\n",
    ")\n",
    "USING DELTA\n",
    "LOCATION '{STORAGE_FOLDER}/{CATALOG}/{RAW_SCHEMA}/transactions'\n",
    "COMMENT 'This table stores transaction information'\n",
    "TBLPROPERTIES ('domain' = 'transaction')\n",
    "\"\"\"\n",
    "\n",
    "# Execute the SQL query\n",
    "spark.sql(create_transactions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f74dac16-8b41-4c49-8469-2f669601ae67",
   "metadata": {},
   "source": [
    "## Create volumes under raw schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "711a19f7-756f-487b-825a-d8294d7d8c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"main\" java.lang.RuntimeException: io.unitycatalog.client.ApiException: createVolume call failed with: 409 - {\"error_code\":\"ALREADY_EXISTS\",\"details\":[{\"reason\":\"ALREADY_EXISTS\",\"metadata\":{},\"@type\":\"google.rpc.ErrorInfo\"}],\"stack_trace\":null,\"message\":\"Volume already exists: unity.raw.json_files\"}\n",
      ".unitycatalog.cli.UnityCatalogCli.main(UnityCatalogCli.java:171)\n",
      "piException: createVolume call failed with: 409 - {\"error_code\":\"ALREADY_EXISTS\",\"details\":[{\"reason\":\"ALREADY_EXISTS\",\"metadata\":{},\"@type\":\"google.rpc.ErrorInfo\"}],\"stack_trace\":null,\"message\":\"Volume already exists: unity.raw.json_files\"}\n",
      "VolumesApi.java:77).client.api.VolumesApi.getApiException(\n",
      "va:117)unitycatalog.client.api.VolumesApi.createVolumeWithHttpInfo(VolumesApi.ja\n",
      "\tat io.unitycatalog.client.api.VolumesApi.createVolume(VolumesApi.java:95)\n",
      "og.cli.VolumeCli.createVolume(VolumeCli.java:74)\n",
      "java:40)nitycatalog.cli.VolumeCli.handle(VolumeCli.\n",
      "\tat io.unitycatalog.cli.UnityCatalogCli.main(UnityCatalogCli.java:133)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume json_files has already existed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"main\" java.lang.RuntimeException: io.unitycatalog.client.ApiException: createVolume call failed with: 409 - {\"error_code\":\"ALREADY_EXISTS\",\"details\":[{\"reason\":\"ALREADY_EXISTS\",\"metadata\":{},\"@type\":\"google.rpc.ErrorInfo\"}],\"stack_trace\":null,\"message\":\"Volume already exists: unity.raw.txt_files\"}\n",
      "\tat io.unitycatalog.cli.UnityCatalogCli.main(UnityCatalogCli.java:171)\n",
      "ient.ApiException: createVolume call failed with: 409 - {\"error_code\":\"ALREADY_EXISTS\",\"details\":[{\"reason\":\"ALREADY_EXISTS\",\"metadata\":{},\"@type\":\"google.rpc.ErrorInfo\"}],\"stack_trace\":null,\"message\":\"Volume already exists: unity.raw.txt_files\"}\n",
      "tion(VolumesApi.java:77)nt.api.VolumesApi.getApiExcep\n",
      "pi.java:117)catalog.client.api.VolumesApi.createVolumeWithHttpInfo(VolumesA\n",
      "\tat io.unitycatalog.client.api.VolumesApi.createVolume(VolumesApi.java:95)\n",
      "catalog.cli.VolumeCli.createVolume(VolumeCli.java:74)\n",
      "eCli.java:40)atalog.cli.VolumeCli.handle(Volum\n",
      "\tat io.unitycatalog.cli.UnityCatalogCli.main(UnityCatalogCli.java:133)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Volume txt_files has already existed\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "cd ${UC_HOME}\n",
    "\n",
    "# Define common paths and names\n",
    "VOLUME_BASE_PATH=\"${STORAGE_FOLDER}/${CATALOG}/${RAW_SCHEMA}/volumes\"\n",
    "\n",
    "# Create folder for storing volumes\n",
    "mkdir -p \"${VOLUME_BASE_PATH}/txt_files\"\n",
    "mkdir -p \"${VOLUME_BASE_PATH}/json_files\"\n",
    "\n",
    "# Function to create volume\n",
    "create_volume() {\n",
    "    local volume_name=$1\n",
    "    local storage_path=$2\n",
    "    local comment=$3\n",
    "\n",
    "    bin/uc volume create \\\n",
    "        --full_name \"${CATALOG}.${RAW_SCHEMA}.${volume_name}\" \\\n",
    "        --storage_location \"${storage_path}\" \\\n",
    "        --comment \"${comment}\" \\\n",
    "    || echo \"Volume ${volume_name} has already existed\"\n",
    "}\n",
    "\n",
    "# Create volumes\n",
    "create_volume \"json_files\" \"${VOLUME_BASE_PATH}/json_files\" \"This volume is used to store json files\"\n",
    "create_volume \"txt_files\" \"${VOLUME_BASE_PATH}/txt_files\" \"This volume is used to store text files\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2877363d-8bdb-4aa8-9f6c-e35374455d98",
   "metadata": {},
   "source": [
    "## Create function(s) under raw schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "edc08fe6-db40-45b9-8d2f-b5026dff9680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function already existed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"main\" java.lang.RuntimeException: io.unitycatalog.client.ApiException: createFunction call failed with: 409 - {\"error_code\":\"ALREADY_EXISTS\",\"details\":[{\"reason\":\"ALREADY_EXISTS\",\"metadata\":{},\"@type\":\"google.rpc.ErrorInfo\"}],\"stack_trace\":null,\"message\":\"Function already exists: hash_text\"}\n",
      "atalog.cli.UnityCatalogCli.main(UnityCatalogCli.java:171)\n",
      "tion: createFunction call failed with: 409 - {\"error_code\":\"ALREADY_EXISTS\",\"details\":[{\"reason\":\"ALREADY_EXISTS\",\"metadata\":{},\"@type\":\"google.rpc.ErrorInfo\"}],\"stack_trace\":null,\"message\":\"Function already exists: hash_text\"}\n",
      ".java:76)itycatalog.client.api.FunctionsApi.getApiException(FunctionsApi\n",
      "16) io.unitycatalog.client.api.FunctionsApi.createFunctionWithHttpInfo(FunctionsApi.java:1\n",
      "\tat io.unitycatalog.client.api.FunctionsApi.createFunction(FunctionsApi.java:94)\n",
      "alog.cli.FunctionCli.createFunction(FunctionCli.java:93)\n",
      "FunctionCli.java:36)cli.FunctionCli.handle(\n",
      "\tat io.unitycatalog.cli.UnityCatalogCli.main(UnityCatalogCli.java:139)\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "cd ${UC_HOME}\n",
    "\n",
    "# Create a python function to hash text\n",
    "bin/uc function create \\\n",
    "    --full_name \"${CATALOG}.${RAW_SCHEMA}.hash_text\" \\\n",
    "    --data_type STRING \\\n",
    "    --input_params \"input_text STRING\" \\\n",
    "    --comment \"This function is used for hashing text\" \\\n",
    "    --language \"python\" \\\n",
    "    --def \"import uuid\\nreturn str(uuid.uuid5(uuid.NAMESPACE_DNS, input_text))\" \\\n",
    "    | echo \"Function already existed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "ff71ff6f-4eda-494b-b551-9a98a4dac52d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Function already existed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread \"main\" java.lang.RuntimeException: io.unitycatalog.client.ApiException: createFunction call failed with: 409 - {\"error_code\":\"ALREADY_EXISTS\",\"details\":[{\"reason\":\"ALREADY_EXISTS\",\"metadata\":{},\"@type\":\"google.rpc.ErrorInfo\"}],\"stack_trace\":null,\"message\":\"Function already exists: customer_full_name\"}\n",
      "io.unitycatalog.cli.UnityCatalogCli.main(UnityCatalogCli.java:171)\n",
      ".ApiException: createFunction call failed with: 409 - {\"error_code\":\"ALREADY_EXISTS\",\"details\":[{\"reason\":\"ALREADY_EXISTS\",\"metadata\":{},\"@type\":\"google.rpc.ErrorInfo\"}],\"stack_trace\":null,\"message\":\"Function already exists: customer_full_name\"}\n",
      "ption(FunctionsApi.java:76)api.FunctionsApi.getApiExce\n",
      "unctionsApi.java:116)lient.api.FunctionsApi.createFunctionWithHttpInfo(F\n",
      "4)t io.unitycatalog.client.api.FunctionsApi.createFunction(FunctionsApi.java:9\n",
      "\tat io.unitycatalog.cli.FunctionCli.createFunction(FunctionCli.java:93)\n",
      "unctionCli.handle(FunctionCli.java:36)\n",
      "java:139)itycatalog.cli.UnityCatalogCli.main(UnityCatalogCli.\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "cd ${UC_HOME}\n",
    "\n",
    "# Create a python function to hash text\n",
    "bin/uc function create \\\n",
    "    --full_name \"${CATALOG}.${RAW_SCHEMA}.customer_full_name\" \\\n",
    "    --data_type STRING \\\n",
    "    --input_params \"first_name STRING, last_name STRING\" \\\n",
    "    --comment \"This function is used for concatenating into customer full name\" \\\n",
    "    --def \"return first_name + ' ' + last_name\" \\\n",
    "    | echo \"Function already existed\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "634cdcd2-dd81-4775-886a-2bb22bff5794",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"Adam West\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%%sh\n",
    "\n",
    "cd ${UC_HOME}\n",
    "\n",
    "# Create a python function to hash text\n",
    "bin/uc function call \\\n",
    "    --full_name \"${CATALOG}.${RAW_SCHEMA}.customer_full_name\" \\\n",
    "    --input_params \"Adam, West\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
